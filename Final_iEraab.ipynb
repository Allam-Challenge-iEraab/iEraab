{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Prompt Notebook with Chat - Prompt Lab Notebook v1.1.0\nThis notebook contains steps and code to demonstrate inferencing of prompts\ngenerated in Prompt Lab in watsonx.ai with a chat format. It introduces Python API commands\nfor authentication using API key and prompt inferencing using WML API.\n\n**Note:** Notebook code generated using Prompt Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Defining parameters of the Model object\n* Using the Model object to generate response using the defined model id, parameters and the prompt input\n\n# Setup"}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://eu-de.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"kliy2ZLKP46T-EtH4mHlU7bX7twpU4LCDGDKaTHYFdgV \")\n\t}\n", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Inferencing\nThis cell demonstrated how we can use the model object as well as the created access token\nto pair it with parameters and input string to obtain\nthe response from the the selected foundation model.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:\n"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"sdaia/allam-1-13b-instruct\"\n", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 900,\n    \"repetition_penalty\": 1\n}", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the Model object\nWe need to define the Model object using the properties we defined so far:\n"}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.foundation_models import Model\n\nmodel = Model(\n\tmodel_id = model_id,\n\tparams = parameters,\n\tcredentials = get_credentials(),\n\tproject_id = project_id,\n\tspace_id = space_id\n\t)\n", "execution_count": 14, "outputs": [{"output_type": "stream", "name": "stdout", "text": "kliy2ZLKP46T-EtH4mHlU7bX7twpU4LCDGDKaTHYFdgV \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install \"pydantic<2.0\"\n!pip install --upgrade fastapi\n!pip install  uvicorn pyngrok nest-asyncio", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: pydantic<2.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (1.10.19)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pydantic<2.0) (4.12.2)\nRequirement already satisfied: fastapi in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (0.115.4)\nRequirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from fastapi) (0.41.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from fastapi) (1.10.19)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from fastapi) (4.12.2)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.6.2.post1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\nRequirement already satisfied: uvicorn in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (0.32.0)\nRequirement already satisfied: pyngrok in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (7.2.1)\nRequirement already satisfied: nest-asyncio in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (1.5.5)\nRequirement already satisfied: click>=7.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from uvicorn) (8.0.4)\nRequirement already satisfied: h11>=0.8 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from uvicorn) (0.14.0)\nRequirement already satisfied: typing-extensions>=4.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from uvicorn) (4.12.2)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from pyngrok) (6.0)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# First Cell - Backend Setup\nimport nest_asyncio\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom pyngrok import ngrok\nimport uvicorn\nimport asyncio\nimport logging\n\n# Apply nest_asyncio at the start\nnest_asyncio.apply()\n\n# Initialize FastAPI app\napp = FastAPI()\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=['*'],\n    allow_credentials=True,\n    allow_methods=['*'],\n    allow_headers=['*'],\n)\n\n# Define data model\nclass ChatRequest(BaseModel):\n    message: str\n\n# Define your endpoints\n@app.get('/')\nasync def root():\n    return {'welcome': 'to iEraab'}\n\n# Define the FastAPI endpoint\n@app.post(\"/chat\")\nasync def chat_endpoint(request: ChatRequest):\n    user_message = request.message\n    prompt = f\"\"\"\n\u0627\u0646\u062a \u0627\u0641\u0636\u0644 \u0645\u062a\u062e\u0635\u0635 \u0641\u0649 \u0627\u0639\u0631\u0627\u0628 \u0627\u0644\u0646\u0635\u0648\u0635 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0627\u0639\u0631\u0627\u0628\u0627 \u0645\u0641\u0635\u0644\u0627 \u0648 \u062f\u0642\u064a\u0642\u0627 \u0648 \u0637\u0628\u0642\u0627 \u0644\u0642\u0648\u0627\u0639\u062f \u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0627\u0644\u0635\u062d\u064a\u062d\u0629.\n\n\u0627\u0644\u0642\u0648\u0627\u0639\u062f:\n- \u0642\u0645 \u0628\u0625\u062c\u0631\u0627\u0621 \u062a\u062d\u0644\u064a\u0644 \u0646\u062d\u0648\u064a \u0648\u0644\u063a\u0648\u064a \u0645\u0641\u0635\u0644 \u0644\u0644\u0646\u0635 \u0627\u0644\u062a\u0627\u0644\u064a \u0628\u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629.\n- \u0642\u0645 \u0628\u0625\u0639\u0631\u0627\u0628 \u0627\u0644\u0646\u0635 \u0625\u0639\u0631\u0627\u0628\u0627 \u0645\u0641\u0635\u0644 \u0648 \u062f\u0642\u064a\u0642.\n- \u0642\u0645 \u0628\u0639\u0631\u0636 \u0627\u0644\u0646\u062a\u0627\u0626\u062c \u0648\u0641\u0642\u0627 \u0644\u0644\u0645\u062b\u0627\u0644 \u0627\u0644\u0639\u0645\u0644\u0649 \u0627\u0644\u0645\u0648\u0636\u062d.\n\n\u0645\u062b\u0627\u0644 \u0639\u0645\u0644\u0649:\n\"\u0645\u0627 \u0623\u0643\u062b\u0631\u064e \u0627\u0644\u0646\u0627\u0633\u064e \u0648\u0645\u0627 \u0623\u0642\u0644\u064e\u0651 \u0627\u0644\u0645\u0641\u064a\u062f\u064e \u0645\u0646\u0647\u0645\"\n\u0645\u0627: \u0627\u0633\u0645 \u062a\u0639\u062c\u0628 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0633\u0643\u0648\u0646 \u0641\u064a \u0645\u062d\u0644 \u0631\u0641\u0639 \u0645\u0628\u062a\u062f\u0623.\n\u0623\u0643\u062b\u0631\u064e: \u0641\u0639\u0644 \u0645\u0627\u0636\u064d \u062c\u0627\u0645\u062f \u0644\u0625\u0646\u0634\u0627\u0621 \u0627\u0644\u062a\u0639\u062c\u0628 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0641\u062a\u062d.\n\u0627\u0644\u0646\u0627\u0633\u064e: \u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0645\u0646\u0635\u0648\u0628 \u0648\u0639\u0644\u0627\u0645\u0629 \u0646\u0635\u0628\u0647 \u0627\u0644\u0641\u062a\u062d\u0629 \u0627\u0644\u0638\u0627\u0647\u0631\u0629 \u0639\u0644\u0649 \u0622\u062e\u0631\u0647.\n\u0648: \u062d\u0631\u0641 \u0639\u0637\u0641 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0641\u062a\u062d.\n\u0645\u0627: \u0627\u0633\u0645 \u062a\u0639\u062c\u0628 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0633\u0643\u0648\u0646 \u0641\u064a \u0645\u062d\u0644 \u0631\u0641\u0639 \u0645\u0628\u062a\u062f\u0623.\n\u0623\u0642\u0644\u064e\u0651: \u0641\u0639\u0644 \u0645\u0627\u0636\u064d \u062c\u0627\u0645\u062f \u0644\u0625\u0646\u0634\u0627\u0621 \u0627\u0644\u062a\u0639\u062c\u0628 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0641\u062a\u062d.\n\u0627\u0644\u0645\u0641\u064a\u062f\u064e: \u0645\u0641\u0639\u0648\u0644 \u0628\u0647 \u0645\u0646\u0635\u0648\u0628 \u0648\u0639\u0644\u0627\u0645\u0629 \u0646\u0635\u0628\u0647 \u0627\u0644\u0641\u062a\u062d\u0629 \u0627\u0644\u0638\u0627\u0647\u0631\u0629 \u0639\u0644\u0649 \u0622\u062e\u0631\u0647.\n\u0645\u0646\u0647\u0645: \u0645\u0646 \u062d\u0631\u0641 \u062c\u0631 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0633\u0643\u0648\u0646\u060c \u0648\"\u0647\u0645\" \u0636\u0645\u064a\u0631 \u0645\u062a\u0635\u0644 \u0645\u0628\u0646\u064a \u0639\u0644\u0649 \u0627\u0644\u0633\u0643\u0648\u0646 \u0641\u064a \u0645\u062d\u0644 \u062c\u0631 \u0628\u062d\u0631\u0641 \u0627\u0644\u062c\u0631. \u0648\u0627\u0644\u062c\u0627\u0631 \u0648\u0627\u0644\u0645\u062c\u0631\u0648\u0631 \u0645\u062a\u0639\u0644\u0642\u0627\u0646 \u0628\u0640 \"\u0627\u0644\u0645\u0641\u064a\u062f\"\n\n\u0627\u0644\u0646\u0635 \u0627\u0644\u0645\u0631\u0627\u062f \u0627\u0639\u0631\u0627\u0628\u0647:    \n{user_message}\n    \"\"\"\n    analysis_result = model.generate_text(prompt=prompt)\n    return {\"response\": analysis_result}\n\n# Set up ngrok first\nauth_token = \"2o1hrQhcITYBZiJMteSIMA0traR_6RHiB2cPxsNXVTPb5xsVX\"\nngrok.set_auth_token(auth_token)\nngrok_tunnel = ngrok.connect(8000)\nprint('Public URL:', ngrok_tunnel.public_url)\n\n", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "Public URL: https://ba0b-158-177-149-228.ngrok-free.app\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "<Task pending name='Task-40' coro=<Server.serve() running at /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages/uvicorn/server.py:67>>"}, "metadata": {}}, {"output_type": "stream", "text": "INFO:     Started server process [267]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nERROR:    [Errno 98] error while attempting to bind on address ('127.0.0.1', 8000): address already in use\nINFO:     Waiting for application shutdown.\nINFO:     Application shutdown complete.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "# Frontend for chat interaction in Jupyter notebook\nfrom IPython.display import display, HTML\n\nhtml_code = f\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>iEraab - Arabic Grammar Analysis</title>\n  <style>\n    @import url('https://fonts.googleapis.com/css2?family=Noto+Kufi+Arabic:wght@400;600;700&display=swap');\n\n    body {{\n      font-family: 'Noto Kufi Arabic', sans-serif;\n      background-color: #f5f5f5;\n    }}\n\n    .container {{\n      max-width: 800px;\n      margin: 0 auto;\n      padding: 40px 20px;\n    }}\n\n    .header {{\n      text-align: center;\n      margin-bottom: 30px;\n    }}\n\n    .header h1 {{\n      color: #0084ff;\n      font-size: 36px;\n      font-weight: 700;\n    }}\n\n    .chat-container {{\n      border: 1px solid #ddd;\n      padding: 20px;\n      height: 450px;\n      overflow-y: auto;\n      background-color: white;\n      border-radius: 10px;\n      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);\n      margin-bottom: 30px;\n    }}\n\n    .user-message, .ai-message {{\n      margin: 12px 0;\n      padding: 12px 16px;\n      border-radius: 20px;\n      max-width: 70%;\n      font-size: 16px;\n      line-height: 1.4;\n    }}\n\n    .user-message {{\n      background-color: #e6f2ff;\n      color: #0077b6;\n      align-self: flex-end;\n    }}\n\n    .ai-message {{\n      background-color: #e6ffe6;\n      color: #006400;\n      align-self: flex-start;\n    }}\n\n    .input-container {{\n      display: flex;\n      align-items: center;\n    }}\n\n    #user-input {{\n      flex-grow: 1;\n      padding: 12px 16px;\n      border: 1px solid #ddd;\n      border-radius: 20px;\n      font-size: 16px;\n    }}\n\n    #send-button {{\n      margin-left: 12px;\n      padding: 12px 24px;\n      background-color: #0084ff;\n      color: white;\n      border: none;\n      border-radius: 20px;\n      cursor: pointer;\n      font-size: 16px;\n      transition: background-color 0.3s;\n    }}\n\n    #send-button:hover {{\n      background-color: #0069d9;\n    }}\n\n    .loading-indicator {{\n      display: none;\n      margin-left: 12px;\n      border: 4px solid #f3f3f3;\n      border-top: 4px solid #3498db;\n      border-radius: 50%;\n      width: 30px;\n      height: 30px;\n      animation: spin 2s linear infinite;\n    }}\n\n    @keyframes spin {{\n      0% {{ transform: rotate(0deg); }}\n      100% {{ transform: rotate(360deg); }}\n    }}\n  </style>\n</head>\n<body>\n  <div class=\"container\">\n    <div class=\"header\">\n      <h1>iEraab - Arabic Grammar Analysis</h1>\n      <p>Unlock the secrets of Arabic grammar with our advanced analysis tool.</p>\n    </div>\n    <div class=\"chat-container\" id=\"chat-container\"></div>\n    <div class=\"input-container\">\n      <input type=\"text\" id=\"user-input\" placeholder=\"Enter your Arabic text here...\" autocomplete=\"off\">\n      <button id=\"send-button\" onclick=\"sendMessage()\">Analyze</button>\n      <div class=\"loading-indicator\" id=\"loading-indicator\"></div>\n    </div>\n  </div>\n\n  <script>\n    const API_URL = '{ngrok_tunnel.public_url}/chat';\n\n    async function sendMessage() {{\n      const input = document.getElementById('user-input');\n      const message = input.value.trim();\n      if (message) {{\n        const chatContainer = document.getElementById('chat-container');\n        const loadingIndicator = document.getElementById('loading-indicator');\n\n        // Display user message\n        const userMessage = document.createElement('div');\n        userMessage.classList.add('user-message');\n        userMessage.textContent = message;\n        chatContainer.appendChild(userMessage);\n\n        loadingIndicator.style.display = 'block';\n        input.value = '';\n\n        try {{\n          const response = await fetch(API_URL, {{\n            method: 'POST',\n            headers: {{\n              'Content-Type': 'application/json'\n            }},\n            body: JSON.stringify({{ message: message }})\n          }});\n\n          if (!response.ok) {{\n            throw new Error(`HTTP error! status: ${{response.status}}`);\n          }}\n\n          const data = await response.json();\n          const analysisResult = data.response || \"No response from API.\";\n\n          const aiMessage = document.createElement('div');\n          aiMessage.classList.add('ai-message');\n          aiMessage.textContent = analysisResult;\n          chatContainer.appendChild(aiMessage);\n        }} catch (error) {{\n          const errorMessage = document.createElement('div');\n          errorMessage.classList.add('ai-message');\n          errorMessage.style.color = 'red';\n          errorMessage.textContent = \"Error: \" + error.message;\n          chatContainer.appendChild(errorMessage);\n        }} finally {{\n          loadingIndicator.style.display = 'none';\n        }}\n\n        chatContainer.scrollTop = chatContainer.scrollHeight;\n      }}\n    }}\n\n    document.getElementById('user-input').addEventListener('keypress', function(event) {{\n      if (event.key === 'Enter') {{\n        sendMessage();\n      }}\n    }});\n  </script>\n</body>\n</html>\n\"\"\"\n\ndisplay(HTML(html_code))", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>iEraab - Arabic Grammar Analysis</title>\n  <style>\n    @import url('https://fonts.googleapis.com/css2?family=Noto+Kufi+Arabic:wght@400;600;700&display=swap');\n\n    body {\n      font-family: 'Noto Kufi Arabic', sans-serif;\n      background-color: #f5f5f5;\n    }\n\n    .container {\n      max-width: 800px;\n      margin: 0 auto;\n      padding: 40px 20px;\n    }\n\n    .header {\n      text-align: center;\n      margin-bottom: 30px;\n    }\n\n    .header h1 {\n      color: #0084ff;\n      font-size: 36px;\n      font-weight: 700;\n    }\n\n    .chat-container {\n      border: 1px solid #ddd;\n      padding: 20px;\n      height: 450px;\n      overflow-y: auto;\n      background-color: white;\n      border-radius: 10px;\n      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);\n      margin-bottom: 30px;\n    }\n\n    .user-message, .ai-message {\n      margin: 12px 0;\n      padding: 12px 16px;\n      border-radius: 20px;\n      max-width: 70%;\n      font-size: 16px;\n      line-height: 1.4;\n    }\n\n    .user-message {\n      background-color: #e6f2ff;\n      color: #0077b6;\n      align-self: flex-end;\n    }\n\n    .ai-message {\n      background-color: #e6ffe6;\n      color: #006400;\n      align-self: flex-start;\n    }\n\n    .input-container {\n      display: flex;\n      align-items: center;\n    }\n\n    #user-input {\n      flex-grow: 1;\n      padding: 12px 16px;\n      border: 1px solid #ddd;\n      border-radius: 20px;\n      font-size: 16px;\n    }\n\n    #send-button {\n      margin-left: 12px;\n      padding: 12px 24px;\n      background-color: #0084ff;\n      color: white;\n      border: none;\n      border-radius: 20px;\n      cursor: pointer;\n      font-size: 16px;\n      transition: background-color 0.3s;\n    }\n\n    #send-button:hover {\n      background-color: #0069d9;\n    }\n\n    .loading-indicator {\n      display: none;\n      margin-left: 12px;\n      border: 4px solid #f3f3f3;\n      border-top: 4px solid #3498db;\n      border-radius: 50%;\n      width: 30px;\n      height: 30px;\n      animation: spin 2s linear infinite;\n    }\n\n    @keyframes spin {\n      0% { transform: rotate(0deg); }\n      100% { transform: rotate(360deg); }\n    }\n  </style>\n</head>\n<body>\n  <div class=\"container\">\n    <div class=\"header\">\n      <h1>iEraab - Arabic Grammar Analysis</h1>\n      <p>Unlock the secrets of Arabic grammar with our advanced analysis tool.</p>\n    </div>\n    <div class=\"chat-container\" id=\"chat-container\"></div>\n    <div class=\"input-container\">\n      <input type=\"text\" id=\"user-input\" placeholder=\"Enter your Arabic text here...\" autocomplete=\"off\">\n      <button id=\"send-button\" onclick=\"sendMessage()\">Analyze</button>\n      <div class=\"loading-indicator\" id=\"loading-indicator\"></div>\n    </div>\n  </div>\n\n  <script>\n    const API_URL = 'https://ca94-158-177-149-228.ngrok-free.app/chat';\n\n    async function sendMessage() {\n      const input = document.getElementById('user-input');\n      const message = input.value.trim();\n      if (message) {\n        const chatContainer = document.getElementById('chat-container');\n        const loadingIndicator = document.getElementById('loading-indicator');\n\n        // Display user message\n        const userMessage = document.createElement('div');\n        userMessage.classList.add('user-message');\n        userMessage.textContent = message;\n        chatContainer.appendChild(userMessage);\n\n        loadingIndicator.style.display = 'block';\n        input.value = '';\n\n        try {\n          const response = await fetch(API_URL, {\n            method: 'POST',\n            headers: {\n              'Content-Type': 'application/json'\n            },\n            body: JSON.stringify({ message: message })\n          });\n\n          if (!response.ok) {\n            throw new Error(`HTTP error! status: ${response.status}`);\n          }\n\n          const data = await response.json();\n          const analysisResult = data.response || \"No response from API.\";\n\n          const aiMessage = document.createElement('div');\n          aiMessage.classList.add('ai-message');\n          aiMessage.textContent = analysisResult;\n          chatContainer.appendChild(aiMessage);\n        } catch (error) {\n          const errorMessage = document.createElement('div');\n          errorMessage.classList.add('ai-message');\n          errorMessage.style.color = 'red';\n          errorMessage.textContent = \"Error: \" + error.message;\n          chatContainer.appendChild(errorMessage);\n        } finally {\n          loadingIndicator.style.display = 'none';\n        }\n\n        chatContainer.scrollTop = chatContainer.scrollHeight;\n      }\n    }\n\n    document.getElementById('user-input').addEventListener('keypress', function(event) {\n      if (event.key === 'Enter') {\n        sendMessage();\n      }\n    });\n  </script>\n</body>\n</html>\n"}, "metadata": {}}, {"output_type": "stream", "text": "INFO:     85.194.96.74:0 - \"OPTIONS /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"OPTIONS /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\nINFO:     85.194.96.74:0 - \"POST /chat HTTP/1.1\" 200 OK\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip ngrok", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "ERROR: unknown command \"ngrok\"\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the inferencing input for chat\nFoundation models supporting chat accept a system prompt that instructs the model on how to conduct the dialog. They also accept previous questions and answers to give additional context when inferencing. Each model has it's own string format for constructing the input.\n\nLet us provide the input we got from the Prompt Lab and format it for the selected model:\n"}, {"metadata": {}, "cell_type": "code", "source": "prompt_input = \"\"\"\"\"\"\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Execution\nLet us now use the defined Model object, pair it with the input, and generate the response to your question:\n"}, {"metadata": {}, "cell_type": "code", "source": "question = input(\"Question: \")\nformattedQuestion = f\"\"\"<s> [INST] {question} [/INST]\"\"\"\nprompt = f\"\"\"{prompt_input}{formattedQuestion}\"\"\"\ngenerated_response = model.generate_text(prompt=prompt, guardrails=False)\nprint(f\"AI: {generated_response}\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.14", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}